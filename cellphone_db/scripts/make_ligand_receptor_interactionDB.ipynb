{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "floating-florist",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: [2021-11-01 18:27:37] receptor_ligand_interactions - Filtered 2809 enzymes in total\n",
      "INFO: [2021-11-01 18:27:37] receptor_ligand_interactions - Total enzymes: 2809\n",
      "INFO: [2021-11-01 18:27:39] receptor_ligand_interactions - Length of Pathway commons enzyme table: 1346675\n",
      "INFO: [2021-11-01 18:27:39] receptor_ligand_interactions - Pathway commons enzyme table after filtering to controls-production-of: 21245\n",
      "INFO: [2021-11-01 18:27:39] receptor_ligand_interactions - Pathway commons enzyme table fater filtering to enzymes in data: 15605\n",
      "INFO: [2021-11-01 18:27:40] receptor_ligand_interactions - Total enzyme-products in data: 3374\n",
      "INFO: [2021-11-01 18:27:44] receptor_ligand_interactions - Enzyme-products receptor targets: 948\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\nenzyme_targets = defaultdict(set)\\nfor k,v in enzyme_product.items():\\n    for p in v:\\n        if p in product_targets.keys():\\n            for i in product_targets[p]:\\n                enzyme_targets[(k)].add(i)\\n\\nlogger.info('Enzyme receptor targets: %d' % (len(enzyme_targets)))\\n\""
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PC_SIF_URL = ('https://www.pathwaycommons.org/archives/PC2/v12/'\n",
    "              'PathwayCommons12.Detailed.hgnc.sif.gz')\n",
    "enzymes = get_all_enzymes()\n",
    "logger.info('Total enzymes: %d' % (len(enzymes)))\n",
    "\n",
    "# Reading pathway commons table\n",
    "pc = pd.read_csv(PC_SIF_URL, sep='\\t', header=None)\n",
    "logger.info('Length of Pathway commons enzyme table: %d' % (len(pc)))\n",
    "\n",
    "pc = pc[pc[1] == 'controls-production-of']\n",
    "logger.info('Pathway commons enzyme table after filtering to controls-production-of: %d' % (len(pc)))\n",
    "\n",
    "boolean_series = pc[0].isin(enzymes)\n",
    "pc = pc[boolean_series]\n",
    "logger.info('Pathway commons enzyme table fater filtering to enzymes in data: %d' % (len(pc)))\n",
    "\n",
    "\n",
    "# create a dictionary for enzymes and its products\n",
    "# and convert the product chebi names into standard chemical\n",
    "# names\n",
    "enzyme_product = defaultdict(set)\n",
    "enzyme_target_df = []\n",
    "for r,c in pc.iterrows():\n",
    "    chebi_name = bio_ontology.get_name('CHEBI', c[2])\n",
    "    enzyme_product[(chebi_name)].add(c[0])\n",
    "\n",
    "\n",
    "# search for enzyme-product target  \n",
    "product_targets = defaultdict(set)\n",
    "products = set(enzyme_product.keys())\n",
    "enzyme_target_df = []\n",
    "logger.info('Total enzyme-products in data: %d' % (len(products)))\n",
    "\n",
    "for a,b,stmt_type,hs,ec in zip(indra_df.agA_name,\n",
    "                               indra_df.agB_name,\n",
    "                               indra_df.stmt_type,\n",
    "                               indra_df.stmt_hash,\n",
    "                               indra_df.evidence_count):\n",
    "    if a in products and b in receptors_in_data:\n",
    "        product_targets[(a)].add(b)\n",
    "        enzyme_target_df.append(\n",
    "            {\n",
    "                'Enzyme': (enzyme_product[a]),\n",
    "                'Product': a,\n",
    "                'Interaction': stmt_type,\n",
    "                'Receptor': b,\n",
    "                'Enzyme_count': len(enzyme_product[a]),\n",
    "                'Evidence_count': ec,\n",
    "                'Statement_hash': hs\n",
    "                \n",
    "            }\n",
    "        )\n",
    "        \n",
    "logger.info('Enzyme-products receptor targets: %d' % (len(product_targets)))\n",
    "\n",
    "'''\n",
    "enzyme_targets = defaultdict(set)\n",
    "for k,v in enzyme_product.items():\n",
    "    for p in v:\n",
    "        if p in product_targets.keys():\n",
    "            for i in product_targets[p]:\n",
    "                enzyme_targets[(k)].add(i)\n",
    "\n",
    "logger.info('Enzyme receptor targets: %d' % (len(enzyme_targets)))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "demanding-teaching",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: [2021-11-01 17:05:21] indra.ontology.bio.ontology - Loading INDRA bio ontology from cache at /Users/sbunga/.indra/bio_ontology/1.12/bio_ontology.pkl\n",
      "INFO: [2021-11-01 17:05:29] receptor_ligand_interactions - Loading INDRA DB dataframe\n",
      "INFO: [2021-11-01 17:05:35] receptor_ligand_interactions - Loaded 6191787 rows from /Users/sbunga/gitHub/panacea_indra/cellphone_db/input/db_dump_df.pkl\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import sys\n",
    "import csv\n",
    "import json\n",
    "import tqdm\n",
    "import pyobo\n",
    "import obonet\n",
    "import random\n",
    "import pickle\n",
    "import logging\n",
    "import graphviz\n",
    "import datetime\n",
    "import openpyxl\n",
    "import networkx\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import enzyme_client\n",
    "from pathlib import Path\n",
    "from matplotlib import rc\n",
    "from bioinfokit import visuz\n",
    "from graphviz import Digraph\n",
    "from indra.sources import tas\n",
    "import matplotlib.pyplot as plt\n",
    "from indra.util import batch_iter\n",
    "from collections import OrderedDict\n",
    "from collections import defaultdict\n",
    "import matplotlib.colors as mcolors\n",
    "from indra.statements import Complex\n",
    "from scipy.stats import fisher_exact\n",
    "from indra.sources import indra_db_rest\n",
    "import indra.tools.assemble_corpus as ac\n",
    "from indra.literature import pubmed_client\n",
    "from indra.assemblers.cx import hub_layout\n",
    "from indra.ontology.bio import bio_ontology\n",
    "from indra.databases.uniprot_client import um\n",
    "from indra.assemblers.html import HtmlAssembler\n",
    "from indra.statements.agent import default_ns_order\n",
    "from indra.sources.omnipath import process_from_web\n",
    "from indra.assemblers.cx.assembler import CxAssembler\n",
    "from indra.databases import uniprot_client, hgnc_client\n",
    "from indra_db.client.principal.curation import get_curations\n",
    "from indra.databases.hgnc_client import get_hgnc_from_mouse, get_hgnc_name\n",
    "\n",
    "\n",
    "logger = logging.getLogger('receptor_ligand_interactions')\n",
    "mouse_gene_name_to_mgi = {v: um.uniprot_mgi.get(k)\n",
    "                          for k, v in um.uniprot_gene_name.items()\n",
    "                          if k in um.uniprot_mgi}\n",
    "db_curations = get_curations()\n",
    "\n",
    "up_hgnc = {v: k\n",
    "           for k, v in um.uniprot_gene_name.items()\n",
    "           if k in um.uniprot_hgnc}\n",
    "\n",
    "__file__ = \"/Users/sbunga/gitHub/panacea_indra/panacea_indra/nextflow/scripts/interactome_notebook.ipynb\"\n",
    "HERE = os.path.abspath(\"/Users/sbunga/gitHub/panacea_indra/cellphone_db/\")\n",
    "INPUT = os.path.join(HERE, 'input')\n",
    "OUTPUT = os.path.join(HERE, 'output')\n",
    "INDRA_DB_PKL = os.path.join(INPUT, 'db_dump_df.pkl')\n",
    "DATA_SPREADSHEET = os.path.join(INPUT, 'Neuroimmune gene list .xlsx')\n",
    "LIGAND_RECEPTOR_SPREADSHEET = os.path.join(INPUT, 'ncomms8866_lg_rg.xlsx')\n",
    "GO_ANNOTATIONS = os.path.join(INPUT, 'goa_human.gaf')\n",
    "DRUG_BANK_PKL = os.path.join(INPUT, 'drugbank_5.1.pkl')\n",
    "ION_CHANNELS = os.path.join(INPUT, 'ion_channels.txt')\n",
    "SURFACE_PROTEINS_WB = os.path.join(INPUT, 'Surface Proteins.xlsx')\n",
    "\n",
    "\n",
    "def _load_goa_gaf():\n",
    "    \"\"\"Load the gene/GO annotations as a pandas data frame.\"\"\"\n",
    "    # goa_ec = {'EXP', 'IDA', 'IPI', 'IMP', 'IGI', 'IEP', 'HTP', 'HDA', 'HMP',\n",
    "    #          'HGI', 'HEP', 'IBA', 'IBD'}\n",
    "    goa = pd.read_csv(GO_ANNOTATIONS, sep='\\t',\n",
    "                      skiprows=23, dtype=str,\n",
    "                      header=None,\n",
    "                      names=['DB',\n",
    "                             'DB_ID',\n",
    "                             'DB_Symbol',\n",
    "                             'Qualifier',\n",
    "                             'GO_ID',\n",
    "                             'DB_Reference',\n",
    "                             'Evidence_Code',\n",
    "                             'With_From',\n",
    "                             'Aspect',\n",
    "                             'DB_Object_Name',\n",
    "                             'DB_Object_Synonym',\n",
    "                             'DB_Object_Type',\n",
    "                             'Taxon',\n",
    "                             'Date',\n",
    "                             'Assigned',\n",
    "                             'Annotation_Extension',\n",
    "                             'Gene_Product_Form_ID'])\n",
    "    goa = goa.sort_values(by=['DB_ID', 'GO_ID'])\n",
    "    # Filter out all \"NOT\" negative evidences\n",
    "    goa['Qualifier'].fillna('', inplace=True)\n",
    "    goa = goa[~goa['Qualifier'].str.startswith('NOT')]\n",
    "    # Filter to rows with evidence code corresponding to experimental\n",
    "    # evidence\n",
    "    # goa = goa[goa['Evidence_Code'].isin(goa_ec)]\n",
    "    return goa\n",
    "\n",
    "\n",
    "goa = _load_goa_gaf()\n",
    "\n",
    "\n",
    "def get_pain_mol():\n",
    "    PAIN_SIGNAL_MOL = {\n",
    "        \"Prostaglandins\": \"CHEBI:26333\",\n",
    "        \"Brandykinin\": \"CHEBI:3165\"\n",
    "    }\n",
    "\n",
    "    CHEBI_LIST = {}\n",
    "    CHEBI_NAMES = {}\n",
    "    for compounds, chebi_id in PAIN_SIGNAL_MOL.items():\n",
    "        CHEBI_LIST[compounds] = \\\n",
    "            [children[1] for children in\n",
    "             bio_ontology.get_children('CHEBI',\n",
    "                                       chebi_id)]\n",
    "\n",
    "        CHEBI_NAMES[compounds] = \\\n",
    "            [bio_ontology.get_name('CHEBI', ids)\n",
    "             for ids in CHEBI_LIST[compounds]]\n",
    "\n",
    "    return CHEBI_NAMES\n",
    "\n",
    "\n",
    "PAIN_MOL_NAMES = get_pain_mol()\n",
    "\n",
    "\n",
    "def load_indra_df(fname):\n",
    "    \"\"\"Return an INDRA Statement data frame from a pickle file.\"\"\"\n",
    "    logger.info('Loading INDRA DB dataframe')\n",
    "    with open(fname, 'rb') as fh:\n",
    "        df = pickle.load(fh)\n",
    "    logger.info('Loaded %d rows from %s' % (len(df), fname))\n",
    "    return df\n",
    "\n",
    "# Load the INDRA DB DF\n",
    "indra_df = load_indra_df(INDRA_DB_PKL)\n",
    "\n",
    "\n",
    "def get_hashes_by_gene_pair(df, ligand_genes, receptor_genes):\n",
    "    hashes_by_gene_pair = defaultdict(set)\n",
    "    l_genes = ligand_genes\n",
    "\n",
    "    for a, b, hs in zip(df.agA_name, df.agB_name, df.stmt_hash):\n",
    "        if a in l_genes and b in receptor_genes:\n",
    "            hashes_by_gene_pair[(a, b)].add(hs)\n",
    "    return hashes_by_gene_pair\n",
    "\n",
    "\n",
    "def download_statements(hashes):\n",
    "    \"\"\"Download the INDRA Statements corresponding to a set of hashes.\n",
    "    \"\"\"\n",
    "    stmts_by_hash = {}\n",
    "    for group in tqdm.tqdm(batch_iter(hashes, 200), total=int(len(hashes) / 200)):\n",
    "        idbp = indra_db_rest.get_statements_by_hash(list(group),\n",
    "                                                    ev_limit=10)\n",
    "        for stmt in idbp.statements:\n",
    "            stmts_by_hash[stmt.get_hash()] = stmt\n",
    "    return stmts_by_hash\n",
    "\n",
    "\n",
    "def get_genes_for_go_ids(go_ids):\n",
    "    \"\"\"Return genes that are annotated with a given go ID or its children.\"\"\"\n",
    "    all_go_ids = set()\n",
    "    for go_id in go_ids:\n",
    "        children_go_ids = {ch[1] for ch in bio_ontology.get_children('GO', go_id)}\n",
    "        all_go_ids.add(go_id)\n",
    "        all_go_ids |= children_go_ids\n",
    "    df = goa[goa['GO_ID'].isin(all_go_ids)]\n",
    "    up_ids = sorted(list(set(df['DB_ID'])))\n",
    "    gene_names = [uniprot_client.get_gene_name(up_id) for up_id in up_ids]\n",
    "    gene_names = {g for g in gene_names if g}\n",
    "    return gene_names\n",
    "\n",
    "\n",
    "def fix_dates(gene_names):\n",
    "    replacements = {\n",
    "        datetime.datetime(2020, 3, 7, 0, 0): 'March7',\n",
    "        datetime.datetime(2020, 3, 2, 0, 0): 'March2',\n",
    "        datetime.datetime(2020, 3, 4, 0, 0): 'March4',\n",
    "        datetime.datetime(2020, 3, 5, 0, 0): 'March5',\n",
    "        datetime.datetime(2020, 3, 6, 0, 0): 'March6',\n",
    "        datetime.datetime(2020, 3, 9, 0, 0): 'March9',\n",
    "        datetime.datetime(2020, 3, 8, 0, 0): 'March8',\n",
    "        datetime.datetime(2020, 3, 11, 0, 0): 'Mar11',\n",
    "        datetime.datetime(2020, 9, 1, 0, 0): 'Sept1',\n",
    "        datetime.datetime(2020, 9, 2, 0, 0): 'Sept2',\n",
    "        datetime.datetime(2020, 9, 3, 0, 0): 'Sept3',\n",
    "        datetime.datetime(2020, 9, 4, 0, 0): 'Sept4',\n",
    "        datetime.datetime(2020, 9, 5, 0, 0): 'Sept5',\n",
    "        datetime.datetime(2020, 9, 6, 0, 0): 'Sept6',\n",
    "        datetime.datetime(2020, 9, 7, 0, 0): 'Sept7',\n",
    "        datetime.datetime(2020, 9, 8, 0, 0): 'Sept8',\n",
    "        datetime.datetime(2020, 9, 9, 0, 0): 'Sept9',\n",
    "        datetime.datetime(2020, 9, 10, 0, 0): 'Sept10',\n",
    "        datetime.datetime(2020, 9, 11, 0, 0): 'Sept11',\n",
    "        datetime.datetime(2020, 9, 15, 0, 0): 'Sept15',\n",
    "    }\n",
    "    fixed_gene_names = set()\n",
    "    for gene_name in gene_names:\n",
    "        if isinstance(gene_name, datetime.datetime):\n",
    "            fixed_gene_names.add(replacements[gene_name])\n",
    "        else:\n",
    "            fixed_gene_names.add(gene_name)\n",
    "    return fixed_gene_names\n",
    "\n",
    "\n",
    "def read_workbook(workbook):\n",
    "    \"\"\" This function takes Excel workbook as an input and\n",
    "    returns ligand and receptor gene list respectively.\n",
    "    Input: Excel workbook with single(2 columns) or two sheets\n",
    "    Condition: considers first column/sheet as ligand genes and second\n",
    "    column/shet as receptor genes\n",
    "    \"\"\"\n",
    "    ligands_sheet = 'updated list of ligands '\n",
    "    receptors_sheet = 'RPKM > 1.5 cfiber'\n",
    "    wb = openpyxl.load_workbook(workbook)\n",
    "    ligands = fix_dates(set([row[0].value for row in wb[ligands_sheet]][1:]))\n",
    "    receptors = fix_dates(set([row[0].value\n",
    "                               for row in wb[receptors_sheet]][1:]))\n",
    "    return ligands, receptors\n",
    "\n",
    "\n",
    "def _plot_de_genes(df):\n",
    "    os.chdir(output_dir)\n",
    "    visuz.gene_exp.volcano(df=df,\n",
    "                           lfc='avg_logFC', pv='p_val',\n",
    "                           plotlegend=True, legendpos='upper right',\n",
    "                           legendanchor=(1.46, 1), geneid=\"Genes\",\n",
    "                           genenames=\"deg\", gstyle=2)\n",
    "\n",
    "\n",
    "def read_gene_list(infile, mode):\n",
    "    gene_list = []\n",
    "    try:\n",
    "        with open(infile, mode) as FH:\n",
    "            for eachGene in FH:\n",
    "                gene_list.append(eachGene.strip(\"\\n\"))\n",
    "        return gene_list\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        sys.exit(\"Given file doesn't exist\")\n",
    "\n",
    "\n",
    "def filter_nuclear_receptors(receptors_go, go_term):\n",
    "    # Filtering out the nuclear receptors from the receptor list\n",
    "    nuclear_receptors = get_genes_for_go_ids([go_term])\n",
    "    # Add any others that don't have the right annotation\n",
    "    nuclear_receptors |= {'NR2C2'}\n",
    "    filtered_receptors_go = receptors_go - nuclear_receptors\n",
    "    return filtered_receptors_go\n",
    "\n",
    "\n",
    "def filter_complex_statements(stmts, ligands, receptors):\n",
    "    for stmt in stmts:\n",
    "        if isinstance(stmt, Complex):\n",
    "            # Statement updated by reference here\n",
    "            _filter_complex(stmt, ligands, receptors)\n",
    "    return stmts\n",
    "\n",
    "\n",
    "def _filter_complex(stmt, lg, rg):\n",
    "    \"\"\"Filter out the genes from Complex statements which\n",
    "    are not present in the given ligand/receptor list\"\"\"\n",
    "    stmt.members = [agent for agent in stmt.members\n",
    "                    if agent.name in lg or agent.name in rg]\n",
    "    return stmt\n",
    "\n",
    "\n",
    "def filter_op_stmts(op_stmts, lg, rg):\n",
    "    \"\"\" Filter out the statements which are not ligand and receptor \"\"\"\n",
    "    logger.info(f'Filtering {len(op_stmts)} to ligand-receptor interactions')\n",
    "    filtered_stmts = [stmt for stmt in op_stmts if\n",
    "                      (any(a.name in lg for a in stmt.agent_list())\n",
    "                       and any(a.name in rg for a in stmt.agent_list()))]\n",
    "    logger.info(f'{len(filtered_stmts)} left after filter')\n",
    "    return filtered_stmts\n",
    "\n",
    "\n",
    "def html_assembler(indra_stmts, fname):\n",
    "    \"\"\"Assemble INDRA statements into a HTML report\"\"\"\n",
    "    html_assembler = HtmlAssembler(indra_stmts,\n",
    "                                   db_rest_url='https://db.indra.bio')\n",
    "    assembled_html_report = html_assembler.make_model(no_redundancy=True)\n",
    "    html_assembler.save_model(fname)\n",
    "    return assembled_html_report\n",
    "\n",
    "\n",
    "def cx_assembler(indra_stmts, fname):\n",
    "    \"\"\"Assemble INDRA statements into a CX report\"\"\"\n",
    "    cx_assembler = CxAssembler(indra_stmts)\n",
    "    assembled_cx_report = cx_assembler.make_model()\n",
    "    cx_assembler.save_model(fname)\n",
    "    ndex_network_id = cx_assembler.upload_model(ndex_cred=None,\n",
    "                                                private=True, style='default')\n",
    "    return assembled_cx_report, ndex_network_id\n",
    "\n",
    "\n",
    "def get_small_mol_report(targets_by_drug, potential_targets, fname):\n",
    "    df = []\n",
    "    for drug, targets in targets_by_drug.items():\n",
    "        targets_in_data = targets & potential_targets\n",
    "        if not targets_in_data:\n",
    "            continue\n",
    "        df.append(\n",
    "            {\n",
    "                \"Drug\": drug[0],\n",
    "                \"ID\": '%s:%s' % (drug[1]),\n",
    "                \"Named\": 0 if drug[0].startswith('CHEMBL') else 1,\n",
    "                \"Score\": \"{:.3f}\".format(len(targets_in_data) / len(targets)),\n",
    "                \"Number of targets in data\": len(targets_in_data),\n",
    "                \"Targets in data\": \", \".join(sorted(targets_in_data)),\n",
    "                \"Other targets\": \", \".join(sorted(targets - targets_in_data)),\n",
    "            }\n",
    "        )\n",
    "    df = pd.DataFrame(df).sort_values(by=['Score', 'Number of targets in data',\n",
    "                                          'Named'],\n",
    "                                      ascending=False)\n",
    "    df.to_csv(fname, sep=\"\\t\", header=True, index=False)\n",
    "    return df\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "def get_ligands_by_receptor(receptors_in_data, ligands_in_data, stmts):\n",
    "    ligands_by_receptor = defaultdict(set)\n",
    "    logFC = list(ligands_in_data.keys())\n",
    "    lg = list(ligands_in_data.values())\n",
    "\n",
    "    for stmt in stmts:\n",
    "        agent_names = {agent.name for agent in stmt.agent_list()}\n",
    "        receptors = agent_names & receptors_in_data\n",
    "        ligands = agent_names & ligands_in_data\n",
    "        for receptor in receptors:\n",
    "            ligands_by_receptor[receptor] |= ligands\n",
    "    return dict(ligands_by_receptor)\n",
    "\"\"\"\n",
    "\n",
    "def get_receptor_by_ligands(receptors_in_data, ligands_in_data, stmts):\n",
    "    receptor_by_ligands = defaultdict(set)\n",
    "    for stmt in stmts:\n",
    "        agent_names = {agent.name for agent in stmt.agent_list()}\n",
    "        receptors = agent_names & receptors_in_data\n",
    "        ligands = agent_names & ligands_in_data\n",
    "        for receptor in receptors:\n",
    "            receptor_by_ligands[receptor] |= ligands\n",
    "    return dict(receptor_by_ligands)\n",
    "\n",
    "\n",
    "def filter_out_medscan(stmts):\n",
    "    logger.info('Filtering out medscan evidence on %d statements' % len(stmts))\n",
    "    new_stmts = []\n",
    "    for stmt in stmts:\n",
    "        new_evidence = [e for e in stmt.evidence if e.source_api != 'medscan']\n",
    "        if not new_evidence:\n",
    "            continue\n",
    "        stmt.evidence = new_evidence\n",
    "        if not stmt.evidence:\n",
    "            continue\n",
    "        new_stmts.append(stmt)\n",
    "    logger.info('%d statements after filter' % len(new_stmts))\n",
    "    return new_stmts\n",
    "\n",
    "\n",
    "def filter_db_only(stmts):\n",
    "    new_stmts = []\n",
    "    for stmt in stmts:\n",
    "        sources = {ev.source_api for ev in stmt.evidence}\n",
    "        if sources <= {'reach', 'sparser', 'trips', 'rlimsp', 'medscan', 'eidos'}:\n",
    "            continue\n",
    "        new_stmts.append(stmt)\n",
    "    return new_stmts\n",
    "\n",
    "\n",
    "def get_cell_type_stats(stmts, ligands, receptors):\n",
    "    interactome = set()\n",
    "    ligand_interactions = defaultdict(set)\n",
    "    for stmt in stmts:\n",
    "        stmt_ligands = {a.name for a in stmt.agent_list() if\n",
    "                        a.name in ligands}\n",
    "        stmt_receptors = {a.name for a in stmt.agent_list() if\n",
    "                          a.name in receptors}\n",
    "        for ligand, receptor in itertools.product(stmt_ligands,\n",
    "                                                  stmt_receptors):\n",
    "            interactome.add((ligand, receptor))\n",
    "            ligand_interactions[ligand].add(receptor)\n",
    "    return len(interactome), ligand_interactions\n",
    "\n",
    "\n",
    "def plot_interaction_potential(num_interactions_by_cell_type, fname):\n",
    "    labels = {\n",
    "        'DCs': 'Dendritic cells',\n",
    "        'Dermal Macs': 'Dermal macrophages',\n",
    "        'M2a': 'Reparative macrophages (2a)',\n",
    "        'M2b': 'Reparative macrophages (2b)',\n",
    "        'Monocytes': 'Monocytes',\n",
    "        'Resident Mac': 'Resident macrophages',\n",
    "        'Mast cells': 'Mast cells'\n",
    "    }\n",
    "    G = networkx.DiGraph()\n",
    "    for cell_type, num_int in num_interactions_by_cell_type.items():\n",
    "        G.add_node(cell_type, label=labels[cell_type])\n",
    "        G.add_edge(cell_type, 'Neurons', label=num_int)\n",
    "    ag = networkx.nx_agraph.to_agraph(G)\n",
    "    ag.draw(fname, prog='dot')\n",
    "\n",
    "\n",
    "def get_all_enzymes():\n",
    "    HOME = str(Path.home())\n",
    "    ec_code_path = '.obo/ec-code/ec-code.obo'\n",
    "    if not os.path.exists(os.path.join(HOME, ec_code_path)):\n",
    "        _ = pyobo.get_id_name_mapping('ec-code')\n",
    "        obo = obonet.read_obo(os.path.join(HOME, ec_code_path))\n",
    "    else:\n",
    "        obo = obonet.read_obo(os.path.join(HOME, ec_code_path))\n",
    "    up_nodes = set()\n",
    "    for node in obo.nodes:\n",
    "        if node.startswith('uniprot'):\n",
    "            up_nodes.add(node[8:])\n",
    "    human_ups = {u for u in up_nodes if uniprot_client.is_human(u)}\n",
    "    enzymes = {uniprot_client.get_gene_name(u) for u in human_ups}\n",
    "    enzymes = {g for g in enzymes if not hgnc_client.is_kinase(g)}\n",
    "    enzymes = {g for g in enzymes if not hgnc_client.is_phosphatase(g)}\n",
    "    logger.info(f'Filtered {len(enzymes)} enzymes in total')\n",
    "    return enzymes\n",
    "\n",
    "\n",
    "def process_seurat_csv(infile, fc):\n",
    "    \"\"\" Process Seurat dataframe and only filter in\n",
    "    genes with the given Fold change \"\"\"\n",
    "    l_df = pd.read_csv(infile, header=0, sep=\",\")\n",
    "    l_df.columns = l_df.columns.str.replace('Unnamed: 0', 'Genes')\n",
    "    filtered_df = l_df[l_df['avg_logFC'] > 0.25][['Genes', 'avg_logFC']]\n",
    "    filtered_df = filtered_df.sort_values(by='avg_logFC', ascending=False)\n",
    "    filtered_dict = {}\n",
    "    for r, c in filtered_df.iterrows():\n",
    "        filtered_dict[c[1]] = c[0]\n",
    "    # Volcano plot of DE genes\n",
    "    _plot_de_genes(l_df)\n",
    "    # return set(filtered_markers)\n",
    "    return filtered_dict\n",
    "\n",
    "\n",
    "def get_de_product_list(de_enzyme_product_list,\n",
    "                        de_enzyme_stmts):\n",
    "    if len(de_enzyme_product_list) > 1:\n",
    "        de_enzyme_product_list = pd.merge(de_enzyme_stmts, de_enzyme_product_list,\n",
    "                                          on=['Enzyme', 'Interaction', 'product', 'logFC'],\n",
    "                                          how=\"outer\").fillna('')\n",
    "        return de_enzyme_product_list.sort_values(by='logFC', ascending=False)\n",
    "\n",
    "    elif len(de_enzyme_product_list) < 1:\n",
    "        de_enzyme_product_list = de_enzyme_stmts\n",
    "        return de_enzyme_product_list\n",
    "\n",
    "\n",
    "def get_enzyme_product_interactions(df, de_en_df, receptors_in_data):\n",
    "    hashes_by_gene_pair = defaultdict(set)\n",
    "    seen_product = set()\n",
    "    product_and_fc = defaultdict(set)\n",
    "    for r, c in de_en_df.iterrows():\n",
    "        if c[2] not in seen_product:\n",
    "            product_and_fc[c[2]].add((c[0], c[3]))\n",
    "        seen_product.add(c[2])\n",
    "\n",
    "    for a, b, hs in zip(df.agA_name, df.agB_name, df.stmt_hash):\n",
    "        if a in product_and_fc and b in receptors_in_data:\n",
    "            enzyme_logFC = [e for v in product_and_fc[a]\n",
    "                            for e in v]\n",
    "            enzyme, logFC = enzyme_logFC[0], enzyme_logFC[1]\n",
    "            hashes_by_gene_pair[(a, b, enzyme, logFC)].add(hs)\n",
    "    return hashes_by_gene_pair\n",
    "\n",
    "\n",
    "def get_pain_phenotype(lg, pain_db):\n",
    "    r_phenotype = defaultdict(set)\n",
    "    for r, c in pain_db.iterrows():\n",
    "        if isinstance(pain_db.iloc[r]['gene_symbols'], str):\n",
    "            l = set(pain_db.iloc[r]['gene_symbols'].split(\",\"))\n",
    "            pheno = pain_db.iloc[r]['phenotype_description']\n",
    "            for g in l:\n",
    "                if g in lg:\n",
    "                    r_phenotype[(g)].add(pheno)\n",
    "    return r_phenotype\n",
    "\n",
    "\n",
    "def make_rnk(infile):\n",
    "    df = pd.read_csv(infile, header=0, sep=\",\")\n",
    "    df.columns = df.columns.str.replace('Unnamed: 0', 'Genes')\n",
    "    df = df.loc[0:, ['Genes', 'p_val']]\n",
    "    return df\n",
    "\n",
    "\n",
    "def make_pheno_file(l_phenotype):\n",
    "    pheno_df = []\n",
    "    for keys, values in l_phenotype.items():\n",
    "        pheno_df.append(\n",
    "            {\n",
    "                \"Receptor\": keys,\n",
    "                \"Phenotype_description\": \", \".join(values)\n",
    "            }\n",
    "        )\n",
    "    return pd.DataFrame(pheno_df)\n",
    "\n",
    "\n",
    "def filter_incorrect_curations(stmts):\n",
    "    # Filter incorrect curations\n",
    "    indra_op_filtered = ac.filter_by_curation(stmts,\n",
    "                                              curations=db_curations)\n",
    "    return indra_op_filtered\n",
    "\n",
    "\n",
    "def ligand_mgi_to_hgnc_name(seurat_ligand_genes):\n",
    "    filtered_mgi = defaultdict(set)\n",
    "    for logfc, gene in seurat_ligand_genes.items():\n",
    "        if gene in mouse_gene_name_to_mgi:\n",
    "            filtered_mgi[(gene, logfc)].add(mouse_gene_name_to_mgi[gene])\n",
    "\n",
    "    hgnc_gene_dict = defaultdict(set)\n",
    "    seen_genes = set()\n",
    "    for key, value in filtered_mgi.items():\n",
    "        mgi_id = next(iter(value))\n",
    "        hgnc_id = get_hgnc_from_mouse(mgi_id)\n",
    "        hgnc_symbol = get_hgnc_name(hgnc_id)\n",
    "        if hgnc_symbol not in seen_genes:\n",
    "            hgnc_gene_dict[(key[1])].add(hgnc_symbol)\n",
    "        else:\n",
    "            pass\n",
    "        seen_genes.add(hgnc_symbol)\n",
    "    return hgnc_gene_dict\n",
    "\n",
    "\n",
    "def mgi_to_hgnc_name(gene_list):\n",
    "    \"\"\"Convert given mouse gene symbols to HGNC equivalent symbols\"\"\"\n",
    "    filtered_mgi = {mouse_gene_name_to_mgi[gene] for gene in gene_list\n",
    "                    if gene in mouse_gene_name_to_mgi}\n",
    "    hgnc_gene_set = set()\n",
    "    for mgi_id in filtered_mgi:\n",
    "        hgnc_id = get_hgnc_from_mouse(mgi_id)\n",
    "        hgnc_gene_set.add(get_hgnc_name(hgnc_id))\n",
    "    return hgnc_gene_set\n",
    "\n",
    "\n",
    "def make_interaction_df(interaction_dict):\n",
    "    interaction_list = [\n",
    "        {\n",
    "            'Agent_A': [stmt[0].agent_list()][0][0].name,\n",
    "            'Agent_B': [stmt[0].agent_list()][0][1].name,\n",
    "            'Interaction type': re.match(\"\\w+\", str(stmt[0])).group(),\n",
    "            'Enzyme': stmt[1],\n",
    "            'logFC': fc\n",
    "        }\n",
    "        for fc, stmts in interaction_dict.items()\n",
    "        for stmt in stmts\n",
    "        if len(stmt[0].agent_list()) > 1\n",
    "\n",
    "    ]\n",
    "    df = pd.DataFrame(interaction_list)\n",
    "    df = df.sort_values(by=['logFC'],\n",
    "                        ascending=False)\n",
    "    return df\n",
    "\n",
    "\n",
    "def create_interaction_digraph(ligand_receptors,\n",
    "                               sorted_enzyme_FC,\n",
    "                               fname):\n",
    "    '''\n",
    "    This function takes two dictionaries as input,\n",
    "    ligand receptors and enzyme fold change and creates\n",
    "    a interaction Digraph of ligands, enzymes and receptors.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    celtype_stmts : Optional[list[indra.statements.Statement]]\n",
    "        A list of INDRA Statements to be assembled.\n",
    "    network_name : Optional[str]\n",
    "        The name of the network to be assembled. Default: indra_assembled\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    ligands_dict : dict\n",
    "        Dict of foldchange and ligands as keys and receptors as values\n",
    "    enzyme dict : dict\n",
    "        Dict of foldchange as keys and enzymes as values\n",
    "    fname : str\n",
    "        output file name\n",
    "    '''\n",
    "\n",
    "    ligand_receptors = dict(sorted(ligand_receptors.items(),\n",
    "                                   reverse=True))\n",
    "    G = networkx.DiGraph()\n",
    "\n",
    "    top_lg_rc = dict(sorted(itertools.islice(ligand_receptors.items(), 10)))\n",
    "    top_en = dict(itertools.islice(sorted_enzyme_FC.items(), 10))\n",
    "\n",
    "    for FC_lg, rcs in top_lg_rc.items():\n",
    "        for rc in rcs:\n",
    "            G.add_node(FC_lg[1], color='green')\n",
    "            G.add_edge(FC_lg[1], rc, label=\"{:.2f}\".format(FC_lg[0]))\n",
    "    for en_FC, en in top_en.items():\n",
    "        for chem in enzyme_product_dict[en]:\n",
    "            for rcs in products_receptors[chem]:\n",
    "                G.add_node(en, color='red')\n",
    "                G.add_edge(en, chem, label=\"{:.2f}\".format(en_FC))\n",
    "                G.add_edge(chem, rcs)\n",
    "\n",
    "    G.graph.setdefault('graph', {})['rankdir'] = 'LR'\n",
    "    ag = networkx.nx_agraph.to_agraph(G)\n",
    "    fname = os.path.join(OUTPUT, fname + \"interactions_digraph.pdf\")\n",
    "    ag.draw(fname, prog='dot')\n",
    "    \n",
    "    \n",
    "def process_df(workbook):\n",
    "    wb = openpyxl.load_workbook(workbook)\n",
    "    df = {\n",
    "    'ligands': [row[1].value for row in wb['All.Pairs']][1:], \n",
    "    'receptors': [row[3].value for row in wb['All.Pairs']][1:]\n",
    "    }\n",
    "    lg_rg = pd.DataFrame(df)\n",
    "    return lg_rg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "collaborative-product",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: [2021-11-01 17:05:35] receptor_ligand_interactions - Got 994 surface proteins from spreadsheet\n",
      "INFO: [2021-11-01 17:05:44] receptor_ligand_interactions - Filtered 2809 enzymes in total\n",
      "INFO: [2021-11-01 17:05:44] receptor_ligand_interactions - Total ligands in data: 988\n"
     ]
    }
   ],
   "source": [
    "wd = '/Users/sbunga/gitHub/panacea_indra/cellphone_db/'\n",
    "\n",
    "# Read and extract cell surface proteins from CSPA DB\n",
    "wb = openpyxl.load_workbook(SURFACE_PROTEINS_WB)\n",
    "surface_protein_set = set(row[4].value for row in wb['Sheet 1']\n",
    "                          if row[6].value == 'yes')\n",
    "logger.info('Got %d surface proteins from spreadsheet' %\n",
    "            len(surface_protein_set))\n",
    "ligand_terms = ['cytokine activity', 'hormone activity',\n",
    "                'growth factor activity']\n",
    "receptor_terms = ['signaling receptor activity']\n",
    "\n",
    "# Getting GO id's for ligands and receptors by using\n",
    "# GO terms\n",
    "ligand_go_ids = [bio_ontology.get_id_from_name('GO', term)[1]\n",
    "                 for term in ligand_terms]\n",
    "receptor_go_ids = [bio_ontology.get_id_from_name('GO', term)[1]\n",
    "                   for term in receptor_terms]\n",
    "\n",
    "# Converting GO id's to gene symbols\n",
    "ligand_genes_go = get_genes_for_go_ids(ligand_go_ids)\n",
    "receptor_genes_go = get_genes_for_go_ids(receptor_go_ids)\n",
    "#manual_ligands = {'THBS1', 'PTGS2'}\n",
    "#manual_receptors = {'PTGER1'}\n",
    "manual_ligands = set()\n",
    "manual_receptors = set()\n",
    "\n",
    "# get enzymes\n",
    "all_enzymes = get_all_enzymes()\n",
    "\n",
    "# remove all the receptors from the surface_protein_set\n",
    "full_ligand_set = \\\n",
    "    (surface_protein_set - receptor_genes_go) | ligand_genes_go | manual_ligands\n",
    "\n",
    "\n",
    "logger.info('Total ligands in data: %d' %(len(full_ligand_set)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "liable-witness",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: [2021-11-01 18:26:30] receptor_ligand_interactions - Total receptors in data: 4154\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\n\\n# Get ligand receptor interactions\\nif os.path.isfile(os.path.join(wd, 'output/pkl/ligand_receptor_stmts.pkl')):\\n    fh = open(os.path.join(wd, 'output/pkl/ligand_receptor_stmts.pkl'), 'rb')\\n    stmts_by_hash = pickle.load(fh)\\nelse:\\n    ligand_receptors_hs = defaultdict(set)\\n    for a,b,hs in zip(indra_df.agA_name,\\n                      indra_df.agB_name,\\n                      indra_df.stmt_hash):\\n        if a in full_ligand_set and b in receptors_in_data:\\n            ligand_receptors_hs[(a, b)].add(hs)\\n    # get the hashes and download statements\\n    all_hashes = set.union(*ligand_receptors_hs.values())\\n    stmts_by_hash = download_statements(all_hashes)\\n    with open(os.path.join(wd, 'output/pkl/ligand_receptor_stmts.pkl'), 'wb') as fh:\\n        pickle.dump(stmts_by_hash, fh)\\n\\nindra_db_stmts = list(stmts_by_hash.values())\\n\\n# Filtering out the indirect INDRA statements\\nindra_db_stmts = ac.filter_direct(indra_db_stmts)\\n\\n\\n# Fetch omnipath database biomolecular interactions and\\n# process them into INDRA statements\\nop = process_from_web()\\n\\n# Filter statements which are not ligands/receptors from \\n# OmniPath database\\nop_filtered = filter_op_stmts(op.statements, full_ligand_set,\\n                              receptors_in_data)\\nop_filtered = ac.filter_direct(op_filtered)\\n\\n# Merge omnipath/INDRA statements and run assembly\\nindra_op_stmts = ac.run_preassembly(indra_db_stmts + op_filtered,\\n                                    run_refinement=False)\\n\\n# Filter incorrect curations\\ndb_curations = get_curations()\\nindra_op_filtered = ac.filter_by_curation(indra_op_stmts,\\n                                          curations=db_curations)\\nindra_op_filtered = filter_complex_statements(indra_op_filtered,\\n                                              full_ligand_set,\\n                                              receptors_in_data)\\n\\n# We do this again because when removing complex members, we\\n# end up with more duplicates\\nindra_op_filtered = ac.run_preassembly(indra_op_filtered,\\n                                       run_refinement=False)\\n\\nreceptor_by_ligands = get_receptor_by_ligands(receptors_in_data, \\n                                              full_ligand_set, \\n                                              indra_op_filtered)\\n\""
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filtering out the nuclear receptors from the receptor list\n",
    "receptor_genes_go = filter_nuclear_receptors(receptor_genes_go,\n",
    "                                             'GO:0004879')\n",
    "\n",
    "\n",
    "# Add ION channels to the receptor list\n",
    "ion_channels = set()\n",
    "with open(ION_CHANNELS, 'r') as fh:\n",
    "    for line in fh:\n",
    "        ion_channels.add(line.strip())\n",
    "receptor_genes_go |= ion_channels\n",
    "\n",
    "# Collect lists of receptors based on GO annotations and\n",
    "# by reading the data\n",
    "# Read list of neuro immune genes from the spread sheet\n",
    "_, raw_receptor_genes = read_workbook(DATA_SPREADSHEET)\n",
    "receptor_genes = mgi_to_hgnc_name(raw_receptor_genes)\n",
    "receptor_genes = receptor_genes | manual_receptors\n",
    "#receptors_in_data = (receptor_genes & receptor_genes_go) | manual_receptors\n",
    "receptors_in_data = receptor_genes_go | manual_receptors\n",
    "logger.info('Total receptors in data: %d' %(len(receptors_in_data)))\n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "# Get ligand receptor interactions\n",
    "if os.path.isfile(os.path.join(wd, 'output/pkl/ligand_receptor_stmts.pkl')):\n",
    "    fh = open(os.path.join(wd, 'output/pkl/ligand_receptor_stmts.pkl'), 'rb')\n",
    "    stmts_by_hash = pickle.load(fh)\n",
    "else:\n",
    "    ligand_receptors_hs = defaultdict(set)\n",
    "    for a,b,hs in zip(indra_df.agA_name,\n",
    "                      indra_df.agB_name,\n",
    "                      indra_df.stmt_hash):\n",
    "        if a in full_ligand_set and b in receptors_in_data:\n",
    "            ligand_receptors_hs[(a, b)].add(hs)\n",
    "    # get the hashes and download statements\n",
    "    all_hashes = set.union(*ligand_receptors_hs.values())\n",
    "    stmts_by_hash = download_statements(all_hashes)\n",
    "    with open(os.path.join(wd, 'output/pkl/ligand_receptor_stmts.pkl'), 'wb') as fh:\n",
    "        pickle.dump(stmts_by_hash, fh)\n",
    "\n",
    "indra_db_stmts = list(stmts_by_hash.values())\n",
    "\n",
    "# Filtering out the indirect INDRA statements\n",
    "indra_db_stmts = ac.filter_direct(indra_db_stmts)\n",
    "\n",
    "\n",
    "# Fetch omnipath database biomolecular interactions and\n",
    "# process them into INDRA statements\n",
    "op = process_from_web()\n",
    "\n",
    "# Filter statements which are not ligands/receptors from \n",
    "# OmniPath database\n",
    "op_filtered = filter_op_stmts(op.statements, full_ligand_set,\n",
    "                              receptors_in_data)\n",
    "op_filtered = ac.filter_direct(op_filtered)\n",
    "\n",
    "# Merge omnipath/INDRA statements and run assembly\n",
    "indra_op_stmts = ac.run_preassembly(indra_db_stmts + op_filtered,\n",
    "                                    run_refinement=False)\n",
    "\n",
    "# Filter incorrect curations\n",
    "db_curations = get_curations()\n",
    "indra_op_filtered = ac.filter_by_curation(indra_op_stmts,\n",
    "                                          curations=db_curations)\n",
    "indra_op_filtered = filter_complex_statements(indra_op_filtered,\n",
    "                                              full_ligand_set,\n",
    "                                              receptors_in_data)\n",
    "\n",
    "# We do this again because when removing complex members, we\n",
    "# end up with more duplicates\n",
    "indra_op_filtered = ac.run_preassembly(indra_op_filtered,\n",
    "                                       run_refinement=False)\n",
    "\n",
    "receptor_by_ligands = get_receptor_by_ligands(receptors_in_data, \n",
    "                                              full_ligand_set, \n",
    "                                              indra_op_filtered)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "essential-celtic",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make indra op interactions dataframe\n",
    "indra_op_interactions = []\n",
    "for receptors, ligands in receptor_by_ligands.items():\n",
    "    for lg in ligands:\n",
    "        indra_op_interactions.append(\n",
    "            {\n",
    "                'ligands':lg,\n",
    "                'receptors': receptors,\n",
    "                'interactions': lg+'_'+receptors\n",
    "            }\n",
    "        )\n",
    "indra_op_df = pd.DataFrame(indra_op_interactions)\n",
    "\n",
    "\n",
    "# get nature interactions and make a dataframe\n",
    "lg_rg = process_df(LIGAND_RECEPTOR_SPREADSHEET)\n",
    "\n",
    "nature_interactome = defaultdict(set)\n",
    "for r,c in lg_rg.iterrows():\n",
    "    nature_interactome[(c[0])].add(c[1])\n",
    "\n",
    "\n",
    "nature_interactions = []\n",
    "for r,c in lg_rg.iterrows():\n",
    "    nature_interactions.append(\n",
    "    {\n",
    "        'ligands': c[0],\n",
    "        'receptors': c[1],\n",
    "        'interactions': c[0]+'_'+c[1]\n",
    "\n",
    "    }\n",
    ")\n",
    "nature_df = pd.DataFrame(nature_interactions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "million-arabic",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# merging indra op and nature interactions\n",
    "unique_interactions = set(indra_op_df.interactions) | set(nature_df.interactions)\n",
    "\n",
    "logger.info('total INDRA OP interactions: %d' % (len(set(indra_op_df.interactions))))\n",
    "logger.info('total nature 2015 interactions: %d' % len(set(nature_df.interactions)))\n",
    "logger.info('total unique interactions: %d' % len(unique_interactions))\n",
    "\n",
    "indra_op_nature = [{'partner_a':i.split('_')[0],\n",
    "                    'partner_b':i.split('_')[1]} \n",
    "                   for i in unique_interactions]\n",
    "\n",
    "indra_op_nature = pd.DataFrame(indra_op_nature)\n",
    "indra_op_nature.to_csv(os.path.join(wd, 'output/indra_op_nature_interactions.csv'), \n",
    "                       sep=\",\", index=0)\n",
    "\n",
    "\n",
    "# make cellphonedb formatted csv file\n",
    "dataframe = []\n",
    "count = 0\n",
    "for r,c in indra_op_nature.iterrows():\n",
    "    count+=1\n",
    "    if c[0] in up_hgnc and c[1] in up_hgnc:\n",
    "        dataframe.append(\n",
    "            {\n",
    "                'id_cp_interaction':'Woolf-'+str(count),\n",
    "                'partner_a': up_hgnc[c[0]],\n",
    "                'partner_b': up_hgnc[c[1]],\n",
    "                'source':'NEURO_IMMUNE_PROJECT'\n",
    "            }\n",
    "        )\n",
    "\n",
    "df = pd.DataFrame(dataframe)\n",
    "df.to_csv(os.path.join(wd, 'output/indra_op_nature_uniprot.csv'), \n",
    "                 sep=\",\", index=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pending-watershed",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "common_op_nature_interaction = set(op_df.interactions) & set(nature_df.interactions)\n",
    "common_op_nature_interaction = pd.DataFrame([{'interactions':i} for i in common_op_nature_interaction])\n",
    "common_op_nature_interaction.to_csv(os.path.join(wd, 'output/common_op_nature_interaction.csv'), \n",
    "                 sep=\",\", index=0)\n",
    "\n",
    "op_specific = set(op_df.interactions) - set(nature_df.interactions)\n",
    "op_specific = pd.DataFrame([{'interactions':i} for i in op_specific])\n",
    "op_specific.to_csv(os.path.join(wd, 'output/op_specific.csv'), \n",
    "                 sep=\",\", index=0)\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
